# Domain Business Rules Updater

## Purpose

Updates or creates AGENT_GUIDE.md and STORY_VALIDATION_CHECKLIST.md files for each domain by analyzing frontend stories and existing documentation using OpenAI's LLM.

## Overview

This script:
1. Reads consolidated frontend stories from `story-work/output/domain-*.txt`
2. Loads existing AGENT_GUIDE.md and STORY_VALIDATION_CHECKLIST.md (if present)
3. Extracts Open Questions from all stories in the domain
4. Submits everything to OpenAI LLM to generate updated documentation
5. Writes updated docs to `domains/{domain}/.business-rules/`

## Prerequisites

- OpenAI API key (set `OPENAI_API_KEY` environment variable)
- `curl` and `jq` installed
- Consolidated story files in `scripts/story-work/output/` (generated by `consolidate-stories-by-domain.sh`)

## Usage

```bash
cd /home/louisb/Projects/durion

# Set your OpenAI API key
export OPENAI_API_KEY="sk-..."

# Process all domains with defaults
./scripts/update-domain-business-rules.sh

# Process a single domain
./scripts/update-domain-business-rules.sh --domain inventory

# Use custom model and longer delay
./scripts/update-domain-business-rules.sh \
  --model gpt-4o \
  --delay 5 \
  --max-tokens 20000

# Dry run to see what would be done
./scripts/update-domain-business-rules.sh --dry-run
```

## Options

| Option | Default | Description |
|--------|---------|-------------|
| `--input-dir DIR` | `./scripts/story-work/output` | Directory containing domain-*.txt files |
| `--domains-dir DIR` | `./domains` | Root directory for domain folders |
| `--model MODEL` | `gpt-4o` | OpenAI model to use |
| `--api-base URL` | `https://api.openai.com/v1` | OpenAI API base URL |
| `--domain NAME` | (all) | Process only this domain (e.g., `inventory`) |
| `--max-chars N` | `120000` | Max characters from story file to send |
| `--max-tokens N` | `16000` | Max tokens for LLM response |
| `--delay SECONDS` | `2` | Delay between API calls (rate limiting) |
| `--dry-run` | false | Show what would be done without calling API |
| `-h, --help` | - | Show help |

## Environment Variables

- `OPENAI_API_KEY` (required): Your OpenAI API key
- `OPENAI_MODEL` (optional): Default model (can be overridden with `--model`)
- `OPENAI_API_BASE` (optional): Custom API endpoint
- `OPENAI_ORG` (optional): OpenAI organization ID

## Output Structure

For each domain, the script creates/updates:

```
domains/{domain}/.business-rules/
├── AGENT_GUIDE.md
└── STORY_VALIDATION_CHECKLIST.md
```

### AGENT_GUIDE.md

Comprehensive guide for domain agents including:
- Domain purpose and boundaries
- Key entities and concepts
- Business rules and invariants
- Event patterns and integrations
- API expectations
- Security and authorization
- Observability guidance
- Testing strategies
- Common pitfalls
- **Open Questions from Frontend Stories** (consolidated)

### STORY_VALIDATION_CHECKLIST.md

Actionable checklist for validating story implementations:
- Scope and ownership verification
- Data model validation
- API contract compliance
- Event handling and idempotency
- Security checks
- Observability requirements
- Performance considerations
- Testing coverage
- Documentation completeness
- **Open Questions to Resolve** (affecting validation)

## How It Works

### 1. Story Input
Reads consolidated stories from `story-work/output/domain-{name}.txt` generated by `consolidate-stories-by-domain.sh`.

### 2. Existing Docs
Checks for existing documentation in `domains/{domain}/.business-rules/`:
- If found: Updates the existing docs
- If not found: Creates new docs from scratch

### 3. Open Questions Extraction
Scans all stories in the domain file for "## Open Questions" sections and extracts them for consolidation.

### 4. LLM Processing
Submits to OpenAI with:
- System prompt (senior staff engineer persona)
- Existing documentation (if any)
- New frontend stories
- Consolidated open questions
- Instructions to update/create specific document

### 5. Rate Limiting
Adds configurable delay between API calls to respect rate limits (default: 2 seconds).

## Example Run

```bash
$ export OPENAI_API_KEY="sk-..."
$ ./scripts/update-domain-business-rules.sh --domain inventory --delay 3

═══════════════════════════════════════════════════════════════
Domain Business Rules Updater
═══════════════════════════════════════════════════════════════
Input: ./scripts/story-work/output
Domains: ./domains
Model: gpt-4o
Max tokens: 16000
Delay between calls: 3s
═══════════════════════════════════════════════════════════════
Found 1 domain files to process

═══════════════════════════════════════════════════════════════
Processing domain: inventory
═══════════════════════════════════════════════════════════════
[INFO] Reading stories from: ./scripts/story-work/output/domain-inventory.txt
[INFO] Output directory: ./domains/inventory/.business-rules
[INFO] Found existing AGENT_GUIDE.md (will update)
[INFO] Found existing STORY_VALIDATION_CHECKLIST.md (will update)
[INFO] Extracting open questions from stories...
[INFO] Found 12 Open Questions sections
[INFO] Calling OpenAI API for AGENT_GUIDE.md...
[OK] Updated: ./domains/inventory/.business-rules/AGENT_GUIDE.md
[INFO] Waiting 3s before next API call...
[INFO] Calling OpenAI API for STORY_VALIDATION_CHECKLIST.md...
[OK] Updated: ./domains/inventory/.business-rules/STORY_VALIDATION_CHECKLIST.md

═══════════════════════════════════════════════════════════════
Summary
═══════════════════════════════════════════════════════════════
Processed: 1
Failed: 0
═══════════════════════════════════════════════════════════════
Done.
```

## Token Considerations

- Default max_tokens: **16000** (same as story_update.py)
- Input is truncated to 120KB per domain file if needed
- Large domains (e.g., workexec with 53 stories) may hit token limits
- Consider using `--max-chars` to reduce input size for very large domains

## Cost Estimation

With gpt-4o pricing (as of Jan 2026):
- ~13 domains × 2 API calls = 26 API calls
- Average ~50K input tokens per call
- Average ~8K output tokens per call
- Estimated cost: $2-5 per complete run (varies by model and story count)

## Error Handling

The script:
- Validates required dependencies (curl, jq)
- Checks for OPENAI_API_KEY
- Verifies input and output directories exist
- Handles HTTP errors from OpenAI API
- Skips empty domain files
- Reports failed domains at the end
- Exits with code 1 if any failures occurred

## Known Issues

- **grep -P requirement**: Uses Perl regex for open questions extraction. May fail on systems without GNU grep.
- **Token limits**: Very large domains may exceed context window even with 120KB truncation.
- **Rate limiting**: Default 2s delay may be too aggressive for free tier. Increase with `--delay`.

## Workflow Integration

This script fits into the larger workflow:

1. **Rewrite stories**: `publish_stories.py` updates GitHub issues
2. **Consolidate by domain**: `consolidate-stories-by-domain.sh` creates domain-*.txt files
3. **Update business rules**: `update-domain-business-rules.sh` (this script) generates agent docs
4. **Agent execution**: Domain agents use AGENT_GUIDE.md and STORY_VALIDATION_CHECKLIST.md

## Related Scripts

- [consolidate-stories-by-domain.sh](./consolidate-stories-by-domain.sh) - Creates domain-*.txt files
- [CONSOLIDATE_STORIES_README.md](./CONSOLIDATE_STORIES_README.md) - Domain consolidation docs
- [publish_stories.py](./publish_stories.py) - Publishes stories to GitHub
- [PUBLISH_STORIES_README.md](./PUBLISH_STORIES_README.md) - Publishing workflow docs

## Troubleshooting

### "Missing required env var: OPENAI_API_KEY"
Set your OpenAI API key:
```bash
export OPENAI_API_KEY="sk-..."
```

### "OpenAI API error (HTTP 429)"
Rate limit exceeded. Increase delay:
```bash
./scripts/update-domain-business-rules.sh --delay 10
```

### "Empty AGENT_GUIDE response"
- Check token limits (increase `--max-tokens`)
- Verify API key is valid
- Check OpenAI service status
- Review truncation warnings (increase `--max-chars`)

### No open questions extracted
This is normal if stories don't have "## Open Questions" sections. The script will still generate docs.

### Incomplete updates
If script fails mid-run, just re-run it. Already-processed domains will be updated again (idempotent).
